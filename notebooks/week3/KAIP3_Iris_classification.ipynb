{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KAIP Week 3 - Tutorial 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Install Cawemo for Business Process Model Notation (for Thursday)\n",
    "https://cawemo.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Supervised Learning Tutorial: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Picture1.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is classification?\n",
    "From Wikipedia : \n",
    "\n",
    "In machine learning and statistics, classification is the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations (or instances) whose category membership is known. Examples are assigning a given email to the \"spam\" or \"non-spam\" class, and assigning a diagnosis to a given patient based on observed characteristics of the patient (sex, blood pressure, presence or absence of certain symptoms, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'week1.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Terminology\n",
    "1. Training, validation and testing set\n",
    "2. Hyperparameter\n",
    "3. Cross-validation, Model Selection\n",
    "4. Activation Function:\n",
    "    - sigmoid\n",
    "    - relu (tomorrow)\n",
    "5. Loss/ Error/ Cost Function\n",
    "    - Cross entropy (binary entropy)\n",
    "    - Hinge Loss\n",
    "6. Optimization methods (i.e. solvers)\n",
    "    - Newton's method\n",
    "    - Stochastic Average Gradient Descent (SAG)\n",
    "    - Variant of Stochastic Average Gradient Descent (SAGA)\n",
    "7. Classifiers:\n",
    "    - K-Nearest Neighbor (KNN)\n",
    "    - Decision Trees (DT)\n",
    "    - Logistic Regression (LR)\n",
    "    - Support Vector Machine (SVM)\n",
    "8. Performance Metrics:\n",
    "    - Accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "In this tutorial, we will look at a a very early dataset, from R.A. Fischer's 1936 paper, \"The Use of Multiple Measurements in Taxonomic Problems\". This dataset consists of different measurements of Iris flowers, with the corresponding species of Iris.\n",
    "It's a nice dataset to get started with because of its simplicity and small size, so we can easily play around with different algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Draw the black box model for the problem of classification of Iris data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Now, let's train some classification models using the Iris dataset!* ðŸ˜ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Import Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_palette('husl')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from KAIP3_classification1_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Iris_augmented.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Data Exploration\n",
    "\n",
    "Let's do some more pandas magic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__: What are the features? What are the labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Features:\\n',data.columns[1:4])\n",
    "print('\\nLabels:')\n",
    "print(data['Species'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "We can get more information about the dataset, including non null variables, memory usage, ... \n",
    "In machine learning, clean and well understood data is absolutely crucial, therefore this information is always good to have.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "We can also use the \"describe\" method to get some statistics on our numerical features, including mean, standard deviation, etc.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Let's make a nice plot of the dataset. <br>\n",
    "__Question__: How do you read this plot?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data.drop('Id', axis=1)\n",
    "g = sns.pairplot(tmp, hue='Species', markers='+')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Id', 'Species'], axis=1)\n",
    "y = data['Species']\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Training models with scikit-learn \n",
    "\n",
    "We will now go through a series of famous and widely used classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Splitting the data\n",
    "\n",
    "First, we need to separate the data into different sets. These are training, validation, and test sets. \n",
    "Remember, the test set is a treasure chest that you need to use only at the very end. However, as you remember from the previous lecture, most algorithms have \"hyperparameters\" you can tune. How to choose the best ones? You just use the validation set for that !\n",
    "\n",
    "<img src = 'data_split_image.png'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.3, random_state=5)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.4, random_state=15)\n",
    "\n",
    "print('Training set contains ' + str(len(y_train)) + ' examples')\n",
    "print('Validation set contains ' + str(len(y_val)) + ' examples')\n",
    "print('Test set contains ' + str(len(y_test)) + ' examples')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. K-nearest-neighbours \n",
    "\n",
    "As our first approach, we will develop what we call a K-Nearest-Neighbors Classifier. This classifier is rarely used in practice, but it will allow us to get an idea about the basic approach to a classification problem.\n",
    "The KNN classifier will take a test datapoint, compare it to every single one of the training datapoints, and predict the label based on a majority vote of the K closest training examples.\n",
    "\n",
    "#### Group exercise\n",
    "Take 10mn with your team to review the main points of the lecture regarding K-nearest-neighbors. Summarize the main ideas and the take home messages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's use a KNN with k = 2\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('The accuracy is ' + str(100*score) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "We've just implemented a KNN in a few lines of codes, which achieved 91% accuracy on the test set. That is, it correctly classified 91% of the flowers in the test set.\n",
    "<br>\n",
    "However, we just randomly set K to be 2. Could we have set it to a better number ? This is where the validation set comes in. We can try different values of K, and look at their performance on the validation set. Then, once we've decided on the prefered value, we can use it on the test set.\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection: How do we select the value of k?\n",
    "Using the validation set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimenting with different k values\n",
    "k_range = list(range(1,30))\n",
    "scores = []\n",
    "models = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_val)\n",
    "    scores.append(metrics.accuracy_score(y_val, y_pred))\n",
    "    models.append(knn)\n",
    "    \n",
    "plt.plot(k_range, scores)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.xlabel('Value of k for KNN', fontsize = 20)\n",
    "plt.ylabel('Accuracy Score', fontsize = 20)\n",
    "plt.title('Accuracy Scores for Values of k of k-Nearest-Neighbors', fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighb = 5\n",
    "\n",
    "y_pred = models[n_neighb-1].predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print('The accuracy is ' + str(100*score) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Indeed, it turns out that n = 2 wasn't the best choice, and we achieve better accuracy on the test set thanks to hyper parameter tuning ! \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "We can now visualize how the model makes its decisions. For that, we will look at only two features: the sepal length and the sepal width, so that we can conveniently plot the data.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighb = 5\n",
    "\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=n_neighb)\n",
    "\n",
    "plot_model_iris(clf_knn, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__ : Visualize the KNN decision boundaries for several number of neighbors. How are the boundaries changing? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Summary__: KNNs work by remembering all the training data and comparing new data to it. An advantage of the KNN is that they are very easy to train and understand. However, this also means that they require a lot of memory, especially for bigger, more realistic datasets, which is very impractical.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Trees\n",
    "\n",
    "\n",
    "Decision trees are a very popular algorithm because of how intuitive they are. As we will see, we can very easily interpret what they do.\n",
    "\n",
    "#### Group exercise\n",
    "Take 10mn with your team to review the main points of the lecture regarding Decision Trees. Summarize the main ideas and the take home messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimenting with different k values\n",
    "depth_range = list(range(1,30))\n",
    "scores = []\n",
    "models = []\n",
    "for d in depth_range:\n",
    "    clf_tree = DecisionTreeClassifier(criterion ='entropy', max_depth = d)\n",
    "    clf_tree.fit(X_train, y_train)\n",
    "    y_pred = clf_tree.predict(X_val)\n",
    "    scores.append(metrics.accuracy_score(y_val, y_pred))\n",
    "    models.append(clf_tree)\n",
    "    \n",
    "plt.plot(depth_range[1:], scores[1:])\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.xlabel('Value of depth for DT', fontsize = 20)\n",
    "plt.ylabel('Accuracy Score', fontsize = 20)\n",
    "plt.title('Accuracy Scores for values of depth for DT', fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 4\n",
    "\n",
    "y_pred = models[depth-1].predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print('The accuracy is ' + str(100*score) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize what the tree with the graphviz library. In the image below you can see how a tree with depth two reaches a decision, if it's only trained on the features \"sepal width\" and \"sepal length\"\n",
    "\n",
    "<img src='decision_tree_plot_iris.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "We can then plot the decision boundaries. Like we've just seen in the graph above, the boundaries are indeed vertical and horizontal lines than allow us to take binary decisions !\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tree = DecisionTreeClassifier(criterion ='entropy', max_depth = 2)\n",
    "\n",
    "plot_model_iris(clf_tree, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Summary__: Decision trees are very easy to interpret, they are so to say a white box! They also have other advantages like automatic feature selection. However, they also suffer from drawbacks such as their tendency to overfit, i.e. fit the noise in the data ! They can also grow very fast for more complex datasets, where they end up losing interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression\n",
    "\n",
    "Logistic regression is a popular classifier, for instance because its outputs can be interpreted as probabilities of a certain class. <br>\n",
    "It is very similiar to the Perceptron you saw in the class. The major advantage is that the activation function of LR is differentiable, as we will see, and we can now do gradient descent more efficiently ! \n",
    "<br>\n",
    "Just like the Perceptron, LR uses a parametric approach: it has a set of parameters (the weights,stored in an array $W$, and the biases $b$), it then takes the inputs $x$, and applies a \"score function\" $z = Wx +b$ . It also has a an activation function called sigmoid $G = 1/1+exp(-z)$. Finally, it has a loss function to compare the output to the label of the training example $y$, which is called the cross entropy loss $ L = y * log(G) - (1 - y)*log(1-G)$. These equations might be intimidating at first, but we'll see that they are very intuitive. For a great view on cross-entropy loss, please refer to this link: https://rdipietro.github.io/friendly-intro-to-cross-entropy-loss/\n",
    "<br>\n",
    "Let's look at a diagram.\n",
    "<img src = 'lr_flow.png'>\n",
    "\n",
    "\n",
    "__Question 1__ :\n",
    "Below is a diagram of the activation function for LR: the sigmoid function $G = 1/1+exp(-z)$\n",
    "<img src = 'sigmoid.png'>\n",
    "This activation function received a score z = Wx + b for a given input. What happens if the score z is high? If it is low? Can you interpret this in terms of probabilities?\n",
    "\n",
    "__Question 2__:\n",
    "Let's now look at the loss function. What is the value of the loss L if our training example is  class 0, but LR outputs a value of 0.1? Replace y and G with these numbers to find out the value of L. \n",
    "If our training is class 0 and LR outputs a value of 0.1? <br> \n",
    "If our training is class 1 and LR outputs class 0.9? <br>\n",
    "If our training is class 1 and LR outputs class 0.1?<br>\n",
    "\n",
    "The advantage of this parametric approach is that once we learn the parameters we can discard the training data. Additionally, the prediction for a new test image is fast since it requires a single matrix multiplication with W, not an exhaustive comparison to every single training example.<br>\n",
    "See these excellent Stanford lecture notes http://cs231n.github.io/linear-classify/ for more details.\n",
    "\n",
    "#### Group exercise\n",
    "Take 10mn with your team to review the main points of the lecture regarding Logistic regression. Summarize the main ideas and the take home messages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr = LogisticRegression(solver='newton-cg', C=1e10, multi_class='multinomial', max_iter = 10000)\n",
    "\n",
    "clf_lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_lr.predict(X_test)\n",
    "score = metrics.accuracy_score(y_pred, y_test)\n",
    "print('The accuracy is ' + str(100*score) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different optimization techniques i.e. solvers\n",
    "solvers = ['newton-cg', 'liblinear', 'sag', 'saga']\n",
    "C = [1e-5, 1e-4, 1e-3, 1e-3, 0.01, 0.1, 1, 10 , 100, 1000, 10000]\n",
    "\n",
    "# Set-up 2x2 grid for plotting.\n",
    "fig, sub = plt.subplots(2, 2, figsize = (10, 8))\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "for solver, ax in zip(solvers, sub.flatten()):\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for c in C:\n",
    "        \n",
    "        clf_lr = LogisticRegression(solver=solver, C=c, max_iter = 10000)\n",
    "        clf_lr.fit(X_train, y_train)\n",
    "        y_pred = clf_lr.predict(X_val)\n",
    "        scores.append(metrics.accuracy_score(y_val, y_pred))\n",
    "       \n",
    "    ax.plot(np.log(C), scores)\n",
    "    ax.set_xlabel('log(C)', fontsize = 14)\n",
    "    ax.set_ylabel('Accuracy (%)', fontsize = 14)    \n",
    "    ax.set_title(solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr = LogisticRegression(solver='newton-cg', C=10, max_iter = 10000)\n",
    "\n",
    "plot_model_iris(clf_lr, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Summary__: LR is a go to algorithm as a first test in many problems. One of its main attractive features is that you can interpret its output as probablities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4. Support Vector Machine (SVM)\n",
    "\n",
    "SVM is another very popular classifier which is very similar to LR, except it has no activation function, and it has a different loss. Indeed, SVM uses the hinge loss, which can not be interpreted as class probabilities. However, it has other very attractive features, such as optimal margins. In practice, LR and SVM give similar results. \n",
    "See these excellent Stanford lecture notes http://cs231n.github.io/linear-classify/ for more details.\n",
    "\n",
    "Let's look at a diagram.\n",
    "\n",
    "<img src = 'svm_flow.png'>\n",
    "\n",
    "__Question__:\n",
    "What is the loss if the label of the training example is 1, and our score function z produces a positive result greater than 1? Between 0 and 1?  A negative result?\n",
    "What is the loss if the label of the training example is -1, and our score function z produces a negative result smaller than -1? Between -1 and 0?  A positive result?\n",
    "<br>\n",
    "An important feature of SVM is that they can be extended to non linear classification (the boundaries would not be straight lines anymore), using the so called \"Kernel trick\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = svm.SVC(kernel = 'linear', C=1, max_iter = 1000000)\n",
    "\n",
    "clf_svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_svm.predict(X_test)\n",
    "score = metrics.accuracy_score(y_pred, y_test)\n",
    "print('The accuracy is ' + str(100*score) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['linear', 'poly', 'rbf']\n",
    "C = [1e-5, 1e-4, 1e-3, 1e-3, 0.01, 0.1, 1, 10 , 100, 1000]\n",
    "\n",
    "# Set-up 2x2 grid for plotting.\n",
    "fig, sub = plt.subplots(2, 2, figsize = (10, 8))\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "for kernel, ax in zip(kernels, sub.flatten()):\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for c in C:\n",
    "        \n",
    "        clf_svm = svm.SVC(kernel = kernel, C=c, max_iter = 1000000)\n",
    "        clf_svm.fit(X_train, y_train)\n",
    "        y_pred = clf_svm.predict(X_val)\n",
    "        scores.append(metrics.accuracy_score(y_val, y_pred))\n",
    "       \n",
    "    ax.plot(np.log(C), scores)\n",
    "    ax.set_xlabel('log(C)', fontsize = 14)\n",
    "    ax.set_ylabel('Accuracy', fontsize = 14)    \n",
    "    ax.set_title(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = svm.SVC(kernel = 'linear', C=10, max_iter = 10000000)\n",
    "\n",
    "plot_model_iris(clf_svm, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Summary__: SVM is a go to algorithm as a first test in many problems. In practice, SVM and LR are usually comparable. The performance difference between the SVM and LR is usually very small, and different people will have different opinions on which classifier works better. An attractive feature of SVM is that is maximize the classification margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
