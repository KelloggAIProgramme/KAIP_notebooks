{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>\n",
       "<!-- Run this cell, it helps with formatting later on -->"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>\n",
    "<!-- Run this cell, it helps with formatting later on -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Introduction to Neural Networks <img src=\"kaip_logo_header.png\" align=\"right\">\n",
    "\n",
    "In this exercise, we will try out some simple Python code to implement *perceptrons* (single artificial neurons) and show how we can link them together to form a *neural network*.\n",
    "\n",
    "Conceptually, a perceptron is a model that is analagous to a biological neuron. The basic function of a biological neuron is to add up its inputs and to produce an output if the sum is greater than some value, known as the *threshold* value. The inputs to a neuron arrive alonge dendrites, which are connected to the output of other neurons via specialised junctions called synapses. These junctions alter the effectiveness with which the signal is passed between neurons. Some synapses are good junctions and pass a larger signal than others. The cell body of a neuron receives these input signals and fires if the input exceeds some threshold value.\n",
    "\n",
    "<img src=\"neuron_schematic.gif\"/>\n",
    "\n",
    "The efficiency of the synapses is modelled by having a multiplicative factor applied to each of the inputs to the neuron, termed a multiplicative *weight*.\n",
    "\n",
    "These model neurons were given the name *perceptron* by Frank Rosenblatt in 1962. \n",
    "\n",
    "<img src=\"single_perceptron.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can model a simple perceptron with two weighted inputs as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_function(x, threshold):\n",
    "    if x < threshold:\n",
    "        return 0\n",
    "    elif x >= threshold:\n",
    "        return 1\n",
    "\n",
    "def sigmoid_function(x1, threshold=0):\n",
    "    import numpy\n",
    "    return round(1 / (1 + numpy.exp(-x1)), 0)\n",
    "\n",
    "class Perceptron2(object):\n",
    "    \"\"\"This class implements a 2-input perceptron.\"\"\"\n",
    "    \n",
    "    def __init__(self, w1, w2, threshold, activation_function):\n",
    "        self.w1 = w1\n",
    "        self.w2 = w2\n",
    "        self.threshold = threshold\n",
    "        self.activation_function = activation_function\n",
    "    \n",
    "    def activate(self, x1, x2):\n",
    "        return self.activation_function(sum([x1 * self.w1, x2 * self.w2]), self.threshold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2 = Perceptron2(0.1, 0.1, 0.5, step_function)\n",
    "p2.activate(0, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, a single input perceptron might be modelled as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Perceptron1(object):\n",
    "    \"\"\"This class implements a 1-input perceptron.\"\"\"\n",
    "    \n",
    "    def __init__(self, w1, threshold, activation_function):\n",
    "        self.w1 = w1\n",
    "        self.threshold = threshold\n",
    "        self.activation_function = activation_function\n",
    "    \n",
    "    def activate(self, x1):\n",
    "        return self.activation_function(x1 * self.w1, self.threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1a = Perceptron1(0.5, 0.5, step_function)\n",
    "p1a.activate(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have constructs for multiples of perceptrons, we can now create our *neural network* of perceptrons by nesting each perceptron's activation function, as follows showing our `Perceptron2` object taking the outputs of two `Perceptron1` objects activating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1b = Perceptron1(0.1, 0.5, step_function)\n",
    "p2.activate(p1a.activate(0), p1b.activate(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generalise our models of perceptrons to allow for arbitrary numbers of inputs, however we must ensure that the the inputs taken by the `activate()` function must always match the number of weights. The model of the weighted inputs should not arbitrarily vary the number of inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Can you implement the logical implementations `and` and `or` using perceptrons?\n",
    "\n",
    "Try modifying the weights. Does the stepwise activation function work in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AND truth table\n",
    "\n",
    "| $P$ | $Q$ | $P$ $\\wedge$ $Q$ |\n",
    "|:---:|:---:|:----------------:|\n",
    "|  T  |  T  |         T        |\n",
    "|  T  |  F  |         F        |\n",
    "|  F  |  T  |         F        |\n",
    "|  F  |  F  |         F        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OR truth table\n",
    "\n",
    "| $P$ | $Q$ | $P$ $\\vee$ $Q$ |\n",
    "|:---:|:---:|:--------------:|\n",
    "|  T  |  T  |        T       |\n",
    "|  T  |  F  |        T       |\n",
    "|  F  |  T  |        T       |\n",
    "|  F  |  F  |        F       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOT truth table\n",
    "\n",
    "| $P$ | $\\neg$ $P$ |\n",
    "|:---:|:----------:|\n",
    "|  T  |      F     |\n",
    "|  F  |      T     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Can you implement the `xor` function?\n",
    "\n",
    "The definition of `a xor b` is:\n",
    "\n",
    "```\n",
    "1, if a and b are different\n",
    "0, if a and b are the same\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XOR truth table\n",
    "\n",
    "| $P$ | $Q$ | $P$ $\\oplus$ $Q$ |\n",
    "|:---:|:---:|:----------------:|\n",
    "|  T  |  T  |         F        |\n",
    "|  T  |  F  |         T        |\n",
    "|  F  |  T  |         T        |\n",
    "|  F  |  F  |         F        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
