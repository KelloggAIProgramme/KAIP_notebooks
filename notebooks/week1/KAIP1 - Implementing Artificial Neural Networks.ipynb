{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>\n",
       "<!-- Run this cell, it helps with formatting later on -->"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>\n",
    "<!-- Run this cell, it helps with formatting later on -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Introduction to Neural Networks <img src=\"kaip_logo_header.png\" align=\"right\">\n",
    "\n",
    "In this exercise, we will try out some simple Python code to implement *perceptrons* (single artificial neurons) and show how we can link them together to form a *neural network*.\n",
    "\n",
    "Conceptually, a perceptron is a model that is analagous to a biological neuron. The basic function of a biological neuron is to add up its inputs and to produce an output if the sum is greater than some value, known as the *threshold* value. The inputs to a neuron arrive alonge dendrites, which are connected to the output of other neurons via specialised junctions called synapses. These junctions alter the effectiveness with which the signal is passed between neurons. Some synapses are good junctions and pass a larger signal than others. The cell body of a neuron receives these input signals and fires if the input exceeds some threshold value.\n",
    "\n",
    "<img src=\"neuron_schematic.gif\"/>\n",
    "\n",
    "The efficiency of the synapses is modelled by having a multiplicative factor applied to each of the inputs to the neuron, termed a multiplicative *weight*.\n",
    "\n",
    "These model neurons were given the name *perceptron* by Frank Rosenblatt in 1962. \n",
    "\n",
    "<img src=\"single_perceptron.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Defining the step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The step function gives an output of 1 when the input exceeds a certain threshold. \n",
    "def step_function(x, threshold):\n",
    "    if x < threshold:\n",
    "        return 0\n",
    "    elif x >= threshold:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're sure you're wondering: how do we choose a threshold depending on the application? Hold that question!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's test generic perceptrons! \n",
    "## 2.2 One-input perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember classes? We can model a simple perceptron with one weighted input as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron1():\n",
    "    \"\"\"This class implements a 1-input perceptron.\"\"\"\n",
    "    \n",
    "    def __init__(self, w1, threshold, activation_function):\n",
    "        self.w1 = w1\n",
    "        self.threshold = threshold\n",
    "        self.activation_function = activation_function\n",
    "    \n",
    "    def activate(self, x1):\n",
    "        output = self.activation_function(x1 * self.w1, self.threshold)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's try a perceptron! Try to change input1 below and check the output!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = 0.5\n",
    "threshold = 2\n",
    "\n",
    "p1 = Perceptron1(w1, threshold, step_function)\n",
    "\n",
    "input1 = 1\n",
    "p1.activate(input1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try changing weight1 and threshold1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-e88d3a26ee4b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-e88d3a26ee4b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    p1.w1 =\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "p1.w1 = \n",
    "p1.threshold = \n",
    "test_input = 1\n",
    "p1.activate(test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Two-input perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can model a simple perceptron with two weighted inputs as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron2():\n",
    "    \"\"\"This class implements a 2-input perceptron.\"\"\"\n",
    "    \n",
    "    def __init__(self, w1, w2, threshold, activation_function):\n",
    "        self.w1 = w1\n",
    "        self.w2 = w2\n",
    "        self.threshold = threshold\n",
    "        self.activation_function = activation_function\n",
    "    \n",
    "    def activate(self, x1, x2):\n",
    "        output = self.activation_function(sum([x1 * self.w1, x2 * self.w2]), self.threshold)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a two-input perceptron! Try changing input1 and input2 below to see how it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = 0.1\n",
    "w2 = 0.1\n",
    "threshold = 0.5\n",
    "p2 = Perceptron2(w1, w2, threshold, step_function)\n",
    "\n",
    "input1 = 0\n",
    "input2 = 1\n",
    "p2.activate(input1, input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try changing weight1, weight2 and the threshold!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2.w1 = \n",
    "p2.w2 =\n",
    "p2.threshold =\n",
    "\n",
    "input1 = 1\n",
    "input2 = 1\n",
    "p2.activate(input1, input2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have constructs for multiples of perceptrons, we can now create our *neural network* of perceptrons by nesting each perceptron's activation function, as follows showing our `Perceptron2` object taking the outputs of two `Perceptron1` objects activating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1cb86a8f93d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput_neuron1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput_neuron2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msecond_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_neuron1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_neuron2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'p2' is not defined"
     ]
    }
   ],
   "source": [
    "first_p = Perceptron1(0.1, 0.5, step_function)\n",
    "second_p = Perceptron1(0.1, 0.5, step_function)\n",
    "\n",
    "output_neuron1 = first_p.activate(0)\n",
    "output_neuron2 = second_p.activate(1)\n",
    "p2.activate(output_neuron1, output_neuron2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generalise our models of perceptrons to allow for arbitrary numbers of inputs, however we must ensure that the the inputs taken by the `activate()` function must always match the number of weights. The model of the weighted inputs should not arbitrarily vary the number of inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's model specific tasks using the perceptrons above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the application, we need to choose the optimal weights and thresholds to get the correct output. <br>\n",
    "\n",
    "We can do this in two ways:\n",
    "\n",
    "    1) Solving a set of equations (which is what we will do here for a few neurons, but imagine if we have a 1000 \n",
    "    neurons - it is too complex!)\n",
    "    2) Learning (This is AI! (i.e. MENACE which learns by playing against itself)) \n",
    "    \n",
    "So, let's solve a simple set of equations now! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Can you implement the logical implementations `and` and `or` using perceptrons?\n",
    "\n",
    "Try modifying the weights. Does the stepwise activation function work in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AND truth table\n",
    "\n",
    "| $P$ | $Q$ | $P$ $\\wedge$ $Q$ |\n",
    "|:---:|:---:|:----------------:|\n",
    "|  T  |  T  |         T        |\n",
    "|  T  |  F  |         F        |\n",
    "|  F  |  T  |         F        |\n",
    "|  F  |  F  |         F        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true and true == true 1\n",
      "true and false == false 0\n",
      "false and true == false 0\n",
      "false and false == false 0\n"
     ]
    }
   ],
   "source": [
    "weight1 = 1 \n",
    "weight2 = 1\n",
    "threshold = 2\n",
    "\n",
    "and_perceptron = Perceptron2(weight1, weight2, threshold, step_function)\n",
    "print(\"true and true == true\", and_perceptron.activate(1, 1))\n",
    "print(\"true and false == false\", and_perceptron.activate(1, 0))\n",
    "print(\"false and true == false\", and_perceptron.activate(0, 1))\n",
    "print(\"false and false == false\", and_perceptron.activate(0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OR truth table\n",
    "\n",
    "| $P$ | $Q$ | $P$ $\\vee$ $Q$ |\n",
    "|:---:|:---:|:--------------:|\n",
    "|  T  |  T  |        T       |\n",
    "|  T  |  F  |        T       |\n",
    "|  F  |  T  |        T       |\n",
    "|  F  |  F  |        F       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true or true == true 1\n",
      "true or false == true 1\n",
      "false or true == true 1\n",
      "false or false == false 0\n"
     ]
    }
   ],
   "source": [
    "weight1 = 1\n",
    "weight2 = 1\n",
    "threshold = 0.9\n",
    "\n",
    "or_perceptron = Perceptron2(weight1, weight2, threshold, step_function)\n",
    "print(\"true or true == true\", or_perceptron.activate(1, 1))\n",
    "print(\"true or false == true\", or_perceptron.activate(1, 0))\n",
    "print(\"false or true == true\", or_perceptron.activate(0, 1))\n",
    "print(\"false or false == false\", or_perceptron.activate(0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOT truth table\n",
    "\n",
    "| $P$ | $\\neg$ $P$ |\n",
    "|:---:|:----------:|\n",
    "|  T  |      F     |\n",
    "|  F  |      T     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not true == false 0\n",
      "not false == true 1\n"
     ]
    }
   ],
   "source": [
    "weight1 = -1\n",
    "threshold = -0.1\n",
    "\n",
    "not_perceptron = Perceptron1(weight1, threshold, step_function)\n",
    "print(\"not true == false\", not_perceptron.activate(1))\n",
    "print(\"not false == true\", not_perceptron.activate(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Can you implement the `xor` function?\n",
    "\n",
    "The definition of `a xor b` is:\n",
    "\n",
    "```\n",
    "1, if a and b are different\n",
    "0, if a and b are the same\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XOR truth table\n",
    "\n",
    "| $P$ | $Q$ | $P$ $\\oplus$ $Q$ |\n",
    "|:---:|:---:|:----------------:|\n",
    "|  T  |  T  |         F        |\n",
    "|  T  |  F  |         T        |\n",
    "|  F  |  T  |         T        |\n",
    "|  F  |  F  |         F        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true xor true == false 0\n",
      "true xor false == true 1\n",
      "false xor true == true 1\n",
      "false xor false == false 0\n"
     ]
    }
   ],
   "source": [
    "def xor_net(input1, input2):\n",
    "    not_input1 = not_perceptron.activate(input1)\n",
    "    not_input2 = not_perceptron.activate(input2)\n",
    "\n",
    "    and_output1 = and_perceptron.activate(input1, not_input2)\n",
    "    and_output2 = and_perceptron.activate(not_input1, input2)\n",
    "    \n",
    "    output = or_perceptron.activate(and_output1, and_output2)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "print(\"true xor true == false\", xor_net(1, 1))\n",
    "print(\"true xor false == true\", xor_net(1, 0))\n",
    "print(\"false xor true == true\", xor_net(0, 1))\n",
    "print(\"false xor false == false\", xor_net(0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
